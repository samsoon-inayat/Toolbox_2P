{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import sys\n",
    "import os\n",
    "import scipy.io\n",
    "# option to import from github folder\n",
    "# sys.path.insert(0, 'E:/Users/samsoon.inayat/T_Drive/GitHub/Downloaded/suite2p/')\n",
    "# from suite2p import run_s2p\n",
    "import suite2p\n",
    "import Thor_Experiment\n",
    "from suite2p import run_s2p, default_ops\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your options for running\n",
    "ops = suite2p.default_ops() # populates ops with the default options\n",
    "# print(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tif data folder where tif files will be extracted from raw data\n",
    "tif_data_folder = 'E:/Users/samsoon.inayat/S_Drive/Tif_Data'\n",
    "# processed_data_folder where the results of suite 2p will be stored\n",
    "#processed_data_folder = 'E:/Users/samsoon.inayat/OneDrive - University of Lethbridge/pySuite2P/processed_data'\n",
    "processed_data_folder = 'E:/Users/samsoon.inayat/S_Drive/Processed_Data'\n",
    "nas_processed_data_folder = 'Z:/homes/brendan.mcallister/2P/Processed_Data_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'recording_list.txt'\n",
    "f = open(filename,'r')\n",
    "dir_names = []\n",
    "for drs in f:\n",
    "    temp = drs[:-1]\n",
    "    tempp = temp.replace(os.sep,os.altsep)\n",
    "    dir_names.append(tempp)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//mohajerani-nas.uleth.ca/storage/homes/samsoon.inayat/Data/183633/2019-06-04/1_001\n",
      "E:/Users/samsoon.inayat/S_Drive/Processed_Data/183633/2019-06-04/1_001\n",
      "Fetching the following parameters from Experiment.xml file \n",
      "\n",
      "//mohajerani-nas.uleth.ca/storage/homes/samsoon.inayat/Data/183633/2019-06-04/1_001\\Experiment.xml\n",
      "['LSM', 'frameRate', 'pixelX', 'pixelY', 'widthUM', 'heightUM']\n",
      "['Timelapse', 'timepoints']\n",
      "['ExperimentNotes', 'text']\n",
      "['Streaming', 'zFastEnable', 'frames']\n",
      "['ZStage', 'steps']\n",
      "\n",
      " Done fetching parameters \n",
      "\n",
      "Loading abf file\n",
      "Processing abf file\n",
      "Successfuly loaded data \n",
      "\n",
      "E:/Users/samsoon.inayat/S_Drive/Processed_Data/183633/2019-06-04/1_001/suite2p/plane0/data.bin\n",
      "Z:/homes/brendan.mcallister/2P/Processed_Data_1/183633/2019-06-04/1_001/suite2p/plane0/data.bin\n",
      "E:/Users/samsoon.inayat/S_Drive/Tif_Data/183633/2019-06-04/1_001\n",
      "42525\n",
      "Number of Planes is 2\n",
      "14175\n",
      "range(0, 42523, 3)\n",
      "\n",
      " Starting conversion raw to tif \n",
      "\n",
      "0\n",
      "42522\n",
      "May be read error\n",
      "\n",
      " Conversion of raw to tif complete \n",
      "\n",
      "14174\n",
      "range(1, 42523, 3)\n",
      "\n",
      " Starting conversion raw to tif \n",
      "\n",
      "\n",
      " Conversion of raw to tif complete \n",
      "\n",
      "{'suite2p_version': '0.9.3', 'look_one_level_down': False, 'fast_disk': [], 'delete_bin': False, 'mesoscan': False, 'bruker': False, 'h5py': [], 'h5py_key': 'data', 'save_path0': 'E:/Users/samsoon.inayat/S_Drive/Processed_Data/183633/2019-06-04/1_001', 'save_folder': [], 'subfolders': [], 'move_bin': False, 'nplanes': 2, 'nchannels': 1, 'functional_chan': 1, 'tau': 1.5, 'fs': 29.16, 'force_sktiff': False, 'frames_include': -1, 'multiplane_parallel': False, 'preclassify': 0.0, 'save_mat': True, 'save_NWB': False, 'combined': True, 'aspect': 1.0, 'do_bidiphase': True, 'bidiphase': 1, 'bidi_corrected': False, 'do_registration': 1, 'two_step_registration': False, 'keep_movie_raw': False, 'nimg_init': 300, 'batch_size': 500, 'maxregshift': 0.1, 'align_by_chan': 1, 'reg_tif': False, 'reg_tif_chan2': False, 'subpixel': 10, 'smooth_sigma_time': 0, 'smooth_sigma': 1.15, 'th_badframes': 1.0, 'norm_frames': True, 'force_refImg': False, 'pad_fft': False, 'nonrigid': True, 'block_size': [128, 128], 'snr_thresh': 1.2, 'maxregshiftNR': 5, '1Preg': False, 'spatial_hp': 42, 'spatial_hp_reg': 42, 'spatial_hp_detect': 25, 'pre_smooth': 0, 'spatial_taper': 40, 'roidetect': True, 'spikedetect': True, 'anatomical_only': False, 'sparse_mode': True, 'diameter': 12, 'spatial_scale': 0, 'connected': True, 'nbinned': 5000, 'max_iterations': 20, 'threshold_scaling': 1.0, 'max_overlap': 0.75, 'high_pass': 100, 'use_builtin_classifier': False, 'neuropil_extract': True, 'inner_neuropil_radius': 2, 'min_neuropil_pixels': 350, 'allow_overlap': False, 'chan2_thres': 0.65, 'baseline': 'maximin', 'win_baseline': 60.0, 'sig_baseline': 10.0, 'prctile_baseline': 8.0, 'neucoeff': 0.7}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'run_s2p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ec2268504163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#     subprocess.call(['python','-u','-W','ignore','-m','suite2p','--ops', 'ops.npy','--db', 'db.npy'],shell=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m#    break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mopsEnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_s2p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_s2p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtif_dir_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtif_dir_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'run_s2p'"
     ]
    }
   ],
   "source": [
    "for x in dir_names:\n",
    "    print(x)\n",
    "    dir_name = x\n",
    "    te = Thor_Experiment.Thor_Exp(dir_name,processed_data_folder,tif_data_folder,nas_processed_data_folder)\n",
    "    data_processing_status = 0\n",
    "    for root, dirs, files in os.walk(te.nas_pd_dir):\n",
    "        for name in files:\n",
    "            if name.endswith((\"Fall.mat\")):\n",
    "                data_processing_status = 1\n",
    "                break\n",
    "    if data_processing_status == 1:\n",
    "        continue\n",
    "#    if te.exp_params.get('zFastEnable') == '1':\n",
    "#        continue\n",
    "#     ops = default_ops()\n",
    "#        print(ops)\n",
    "    ops.update({'nplanes':te.exp_params.get('nplanes')})\n",
    "    ops.update({'save_path0':te.pd_dir})\n",
    "    ops.update({'fs':float(te.exp_params.get('frameRate'))})\n",
    "    ops.update({'save_mat':True})\n",
    "    mat = scipy.io.loadmat(te.nas_pd_dir + '/bidishift.mat')\n",
    "    bidishift = mat['bidishift'];\n",
    "#    print(bidishift[0][0])\n",
    "#    break\n",
    "    ops.update({'do_bidiphase':True})\n",
    "    ops.update({'bidiphase':bidishift[0][0]})\n",
    "    ops.update({'roidetect':True})\n",
    "    ops.update({'do_registration':1})\n",
    "    ops.update({'tau':1.5})\n",
    "    print(ops)\n",
    "    db = {\n",
    "            'h5py': [], # a single h5 file path\n",
    "            'h5py_key': 'data',\n",
    "            'data_path': [te.tif_dir_name], # a list of folders with tiffs\n",
    "                                         # (or folder of folders with tiffs if look_one_level_down is True, or subfolders is not empty)\n",
    "            }\n",
    "    np.save('ops.npy', ops)\n",
    "    np.save('db.npy', db)\n",
    "#     subprocess.call(['python','-u','-W','ignore','-m','suite2p','--ops', 'ops.npy','--db', 'db.npy'],shell=True)\n",
    "#    break\n",
    "    opsEnd = run_s2p(ops = ops,db = db)\n",
    "    if os.path.exists(te.tif_dir_name):\n",
    "        shutil.rmtree(te.tif_dir_name)\n",
    "    else:\n",
    "        print('tif folder already removed')\n",
    "    del(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# provide an h5 path in 'h5py' or a tiff path in 'data_path'\n",
    "# db overwrites any ops (allows for experiment specific settings)\n",
    "db = {\n",
    "      'h5py': [], # a single h5 file path\n",
    "      'h5py_key': 'data',\n",
    "      'look_one_level_down': False, # whether to look in ALL subfolders when searching for tiffs\n",
    "      'data_path': ['C:/Users/carse/github/tiffs'], # a list of folders with tiffs \n",
    "                                             # (or folder of folders with tiffs if look_one_level_down is True, or subfolders is not empty)\n",
    "                                            \n",
    "      'subfolders': [], # choose subfolders of 'data_path' to look in (optional)\n",
    "      'fast_disk': 'C:/BIN', # string which specifies where the binary file will be stored (should be an SSD)\n",
    "    }\n",
    "\n",
    "# run one experiment\n",
    "opsEnd=run_s2p.run_s2p(ops=ops,db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of db's and loop over them\n",
    "db = []\n",
    "db.append({'data_path': ['C:/Users/carse/github/tiffs']})\n",
    "db.append({'data_path': ['C:/Users/carse/github/tiffs2']})\n",
    "\n",
    "for dbi in db:\n",
    "    opsEnd=run_s2p.run_s2p(ops=ops,db=dbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run on specified tiffs\n",
    "db = {\n",
    "      'h5py': [], # a single h5 file path\n",
    "      'h5py_key': 'data',\n",
    "      'look_one_level_down': False, # whether to look in ALL subfolders when searching for tiffs\n",
    "      'data_path': ['C:/Users/carse/github/tiffs/'], \n",
    "                    # a list of folders with tiffs \n",
    "                    # (or folder of folders with tiffs if look_one_level_down is True, or subfolders is not empty)        \n",
    "      'subfolders': [], # choose subfolders of 'data_path' to look in (optional)\n",
    "      'fast_disk': 'C:/BIN', # string which specifies where the binary file will be stored (should be an SSD)\n",
    "      'tiff_list': ['file022.tif', 'file023.tif'] # list of tiffs in folder * data_path *!\n",
    "    }\n",
    "\n",
    "\n",
    "# run one experiment\n",
    "opsEnd=run_s2p.run_s2p(ops=ops,db=db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of all files in your folder (starting with 73.)\n",
    "### *** this is for files that don't end with *.tif or *.tiff ***\n",
    "\n",
    "import glob, os\n",
    "froot = '/media/carsen/DATA2/grive/suite2p_test/example-tiffs-metafluor/'\n",
    "files = glob.glob(os.path.join(froot, \"73.*\"))\n",
    "for n,f in enumerate(files):\n",
    "    files[n] = os.path.basename(f)\n",
    "    \n",
    "db = {\n",
    "      'h5py': [], # a single h5 file path\n",
    "      'h5py_key': 'data',\n",
    "      'look_one_level_down': False, # whether to look in ALL subfolders when searching for tiffs\n",
    "      'data_path': [froot], \n",
    "                            # a list of folders with tiffs \n",
    "                            # (or folder of folders with tiffs if look_one_level_down is True, or subfolders is not empty)\n",
    "                            \n",
    "      'subfolders': [], # choose subfolders of 'data_path' to look in (optional)\n",
    "      'tiff_list': files # list of tiffs in folder * data_path *!\n",
    "    }\n",
    "\n",
    "\n",
    "# run one experiment\n",
    "opsEnd=run_s2p.run_s2p(ops=ops,db=db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change the save directory from 'suite2p' to a chosen name\n",
    "# note the fast_disk will always be in 'suite2p', just the save_path will change\n",
    "\n",
    "ops = run_s2p.default_ops() # populates ops with the default options\n",
    "ops['sparse_mode'] = 1\n",
    "ops['threshold_scaling'] = 3.0\n",
    "db = {\n",
    "      'h5py': [], # a single h5 file path\n",
    "      'h5py_key': 'data',\n",
    "      'look_one_level_down': False, # whether to look in ALL subfolders when searching for tiffs\n",
    "      'data_path': ['D:/DATA/GT1/singlechannel_half/'], # a list of folders with tiffs \n",
    "                # (or folder of folders with tiffs if look_one_level_down is True, or subfolders is not empty)\n",
    "      'save_folder': 'suite2p_sparse_mode'\n",
    "    }\n",
    "\n",
    "# run one experiment\n",
    "opsEnd=run_s2p.run_s2p(ops=ops,db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5py file with multiple data fields (untested)\n",
    "\n",
    "ops = run_s2p.default_ops() # populates ops with the default options\n",
    "ops['nplanes'] = 12\n",
    "ops['nchannels'] = 2\n",
    "ops['fs'] = 5.0\n",
    "\n",
    "db = {\n",
    "      'h5py': 'C:/Users/carse/H5/data1.h5', # a single h5 file \n",
    "      'h5py_key': ['data'], # list of keys to use (they will be extracted in the order you give them)\n",
    "      'look_one_level_down': True, # for h5 files, whether to use all files in same folder\n",
    "      'data_path': [] # keep this empty!\n",
    "    }\n",
    "\n",
    "# run one experiment\n",
    "opsEnd=run_s2p.run_s2p(ops=ops,db=db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
